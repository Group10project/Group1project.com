import os
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error

# Download and Load Data
HOUSING_PATH = r"C:\Users\mawan\OneDrive - University of Zululand - Students\UNIZULU\Year 3\Semester 1\Advanced Programming Techniques\Project 1\datasets\housing\housing"

def load_housing_data(housing_path=HOUSING_PATH):
    csv_path = os.path.join(housing_path, "housing.csv")
    return pd.read_csv(csv_path)

housing = load_housing_data()
housing.info()

# Data Processing
housing_labels = housing["median_house_value"].copy()
housing = housing.drop("median_house_value", axis=1)

# Split the dataset into training and testing sets
housing_train, housing_test, labels_train, labels_test = train_test_split(housing, housing_labels, test_size=0.2, random_state=42)

# Numerical and Categorical Features
housing_num = housing_train.drop("ocean_proximity", axis=1)
housing_cat = housing_train[["ocean_proximity"]]

# Numerical Pipeline
num_pipeline = Pipeline([
    ('imputer', SimpleImputer(strategy="median")),
    ('std_scaler', StandardScaler()),
])

# Full Pipeline
full_pipeline = ColumnTransformer([
    ("num", num_pipeline, housing_num.columns),
    ("cat", OneHotEncoder(), ["ocean_proximity"]),
])

# Prepare the training data
housing_prepared = full_pipeline.fit_transform(housing_train)

# Train Model
forest_reg = RandomForestRegressor()
forest_reg.fit(housing_prepared, labels_train)

# Prepare the test data
housing_test_prepared = full_pipeline.transform(housing_test)

# Make predictions
housing_predictions = forest_reg.predict(housing_test_prepared)

# Evaluate Model
forest_mse = mean_squared_error(labels_test, housing_predictions)
forest_rmse = np.sqrt(forest_mse)
print("RMSE on test set:", forest_rmse)
